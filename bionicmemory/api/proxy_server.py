from contextlib import asynccontextmanager
import os
import json
import logging
import asyncio
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
import httpx
from fastapi import FastAPI, Request, Response, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
import uvicorn

from bionicmemory.core.memory_system import LongShortTermMemorySystem, SourceType
from bionicmemory.services.memory_cleanup_scheduler import MemoryCleanupScheduler
from bionicmemory.core.chroma_service import ChromaService
from bionicmemory.algorithms.newton_cooling_helper import CoolingRate
from bionicmemory.services.local_embedding_service import get_embedding_service

def extract_user_message(messages: List[Dict]) -> Optional[str]:
    """ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–ç”¨æˆ·æ¶ˆæ¯"""
    for message in reversed(messages):  # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹æŸ¥æ‰¾
        if message.get("role") == "user":
            return message.get("content", "")
    return None

def extract_user_id_from_request(body_data: Dict) -> str:
    """ä»OpenAIè¯·æ±‚ä¸­æå–ç”¨æˆ·ID"""
    try:
        logger.info("ğŸ” å¼€å§‹æå–ç”¨æˆ·ID...")
        
        # 1. ä¼˜å…ˆä»å¯¹è¯åè®®ä¸­çš„userå­—æ®µæå–
        if "user" in body_data:
            raw_user = body_data["user"]
            if isinstance(raw_user, str) and raw_user.strip():
                user_id = raw_user.strip()
                logger.info(f"âœ… ä½¿ç”¨å¯¹è¯åè®®userå­—æ®µ: {user_id}")
                return user_id
        
        # 2. é»˜è®¤å€¼ï¼šdefault_user
        user_id = "default_user"
        logger.info(f"âœ… ä½¿ç”¨é»˜è®¤ç”¨æˆ·ID: {user_id}")
        return user_id
        
    except Exception as e:
        logger.error(f"âŒ æå–ç”¨æˆ·IDå¤±è´¥: {e}")
        return "default_user"

def enhance_chat_with_memory(body_data: Dict, user_id: str) -> Tuple[Dict, List[float]]:
    """
    ä½¿ç”¨è®°å¿†ç³»ç»Ÿå¢å¼ºèŠå¤©è¯·æ±‚
    
    Args:
        body_data: è¯·æ±‚ä½“æ•°æ®
        user_id: ç”¨æˆ·ID
        api_key: APIå¯†é’¥
    
    Returns:
        (å¢å¼ºåçš„body_data, enhanced_query_embedding)
    """
    global memory_system
    
    if not memory_system:
        logger.warning("âš ï¸ è®°å¿†ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè·³è¿‡è®°å¿†å¢å¼º")
        return body_data, None
    
    try:
        messages = body_data.get("messages", [])
        if not messages:
            return body_data, None
        
        # æå–ç”¨æˆ·æ¶ˆæ¯
        user_message = extract_user_message(messages)
        if not user_message:
            return body_data, None
        
        # ä½¿ç”¨è®°å¿†ç³»ç»Ÿå¤„ç†ç”¨æˆ·æ¶ˆæ¯
        short_term_records, system_prompt, query_embedding = memory_system.process_user_message(
            user_message, user_id
        )
        
        if short_term_records:
            logger.info(f"ğŸ§  æ‰¾åˆ° {len(short_term_records)} æ¡ç›¸å…³è®°å¿†")
            logger.info(f"ğŸ§  ç”Ÿæˆçš„ç³»ç»Ÿæç¤ºè¯­é•¿åº¦: {len(system_prompt)}")
            
            # ç›´æ¥ä½¿ç”¨memory_systemç”Ÿæˆçš„ç³»ç»Ÿæç¤ºè¯­ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯
            system_message = {
                "role": "system",
                "content": system_prompt
            }
            
            # åœ¨ç”¨æˆ·æ¶ˆæ¯å‰æ’å…¥ç³»ç»Ÿæ¶ˆæ¯
            enhanced_messages = [system_message] + (messages[-3:] if len(messages) > 3 else messages)
            body_data["messages"] = enhanced_messages
            
            logger.info(f"ğŸ§  è®°å¿†å¢å¼ºå®Œæˆï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)} -> {len(enhanced_messages)}")
            logger.info(f"ğŸ§  è®°å¿†å¢å¼ºå®Œæˆï¼Œæ¶ˆæ¯å†…å®¹: {enhanced_messages}")
        
        return body_data, query_embedding
        
    except Exception as e:
        logger.error(f"âŒ è®°å¿†å¢å¼ºå¤±è´¥: {e}")
        return body_data, None

async def process_ai_reply_async(response_content: str, user_id: str, current_user_content: str = None):
    """å¼‚æ­¥å¤„ç†AIå›å¤ï¼ˆä¸é˜»å¡å“åº”æ€§èƒ½ï¼‰"""
    global memory_system
    
    if not memory_system:
        return
    
    try:
        # æ‰§è¡Œè®°å¿†ç³»ç»Ÿå¤„ç†ï¼ˆæ­£ç¡®çš„ä¸šåŠ¡é€»è¾‘é¡ºåºï¼‰
        await memory_system.process_agent_reply_async(response_content, user_id, current_user_content)
        
    except Exception as e:
        logger.error(f"âŒ å¼‚æ­¥å¤„ç†AIå›å¤å¤±è´¥: {e}")

# ä½¿ç”¨ç»Ÿä¸€æ—¥å¿—é…ç½®
from bionicmemory.utils.logging_config import get_logger
logger = get_logger(__name__)

# ========== ç¯å¢ƒå˜é‡é…ç½® ==========
# ç¦ç”¨ChromaDBé¥æµ‹
os.environ["ANONYMIZED_TELEMETRY"] = "False"

API_HOST = os.getenv("API_HOST", "0.0.0.0")
API_PORT = int(os.getenv("API_PORT", "8000"))
CHROMA_HOST = os.getenv("CHROMA_HOST", "localhost")
CHROMA_PORT = int(os.getenv("CHROMA_PORT", "8001"))
CHROMA_CLIENT_TYPE = os.getenv("CHROMA_CLIENT_TYPE", "persistent")

# ========== ChatCompletion é…ç½® ==========
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_API_BASE = os.getenv("OPENAI_API_BASE", "https://api.deepseek.com")
OPENAI_MODEL_NAME = os.getenv("OPENAI_MODEL_NAME", "deepseek-chat")

# ========== Embedding é…ç½® ==========
# ç§»é™¤è¿œç¨‹embeddingé…ç½®ï¼Œåªä½¿ç”¨æœ¬åœ°embedding

# è®°å¿†ç³»ç»Ÿé…ç½®
# è®°å¿†ç³»ç»Ÿé…ç½®
SUMMARY_MAX_LENGTH = int(os.getenv('SUMMARY_MAX_LENGTH', '500'))
MAX_RETRIEVAL_RESULTS = int(os.getenv('MAX_RETRIEVAL_RESULTS', '7'))
CLUSTER_MULTIPLIER = int(os.getenv('CLUSTER_MULTIPLIER', '3'))
RETRIEVAL_MULTIPLIER = int(os.getenv('RETRIEVAL_MULTIPLIER', '2'))
# ç”Ÿå‘½å‘¨æœŸäº‹ä»¶å¤„ç†å™¨
@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    initialize_memory_system()
    yield
    # å…³é—­æ—¶æ¸…ç†
    if memory_cleanup_scheduler:
        memory_cleanup_scheduler.stop()
        logger.info("è®°å¿†æ¸…ç†è°ƒåº¦å™¨å·²åœæ­¢")

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(title="ChromaWithForgetting Memory System", version="1.0.0", lifespan=lifespan)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
memory_system = None
memory_cleanup_scheduler = None
chroma_service = None

# åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
def initialize_memory_system():
    global memory_system, memory_cleanup_scheduler, chroma_service
    
    try:
        logger.info("æ­£åœ¨åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–ChromaDBæœåŠ¡ï¼ˆåªä½¿ç”¨æœ¬åœ°embeddingï¼‰
        chroma_service = ChromaService()
        logger.info("ChromaDBæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ˆæœ¬åœ°embeddingæ¨¡å¼ï¼‰")
        
        # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
        memory_system = LongShortTermMemorySystem(
            chroma_service=chroma_service,
            summary_threshold=SUMMARY_MAX_LENGTH,
            max_retrieval_results=MAX_RETRIEVAL_RESULTS,
            cluster_multiplier=CLUSTER_MULTIPLIER,
            retrieval_multiplier=RETRIEVAL_MULTIPLIER,
        )
        
        # å¯åŠ¨æ—¶æ¸…ç©ºçŸ­æœŸè®°å¿†åº“
        try:
            # æ¸…ç©ºçŸ­æœŸè®°å¿†åº“
            short_term_deleted_ids = chroma_service.delete_documents(
                memory_system.short_term_collection_name
            )
            logger.info(f"å¯åŠ¨æ¸…ç©ºçŸ­æœŸè®°å¿†åº“ï¼Œåˆ é™¤ {len(short_term_deleted_ids)} æ¡è®°å½•")
            
        except Exception as _e:
            logger.warning("å¯åŠ¨æ¸…ç©ºçŸ­æœŸè®°å¿†åº“å¤±è´¥", exc_info=True)
        
        # åˆå§‹åŒ–æ¸…ç†è°ƒåº¦å™¨
        # ä½¿ç”¨ç§‘å­¦ç®—æ³•ï¼Œä¸å†éœ€è¦æ‰‹åŠ¨é…ç½®å‚æ•°
        memory_cleanup_scheduler = MemoryCleanupScheduler(memory_system=memory_system)
        memory_cleanup_scheduler.start()
        
        logger.info("è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        return True
    except Exception as e:
        logger.error(f"è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}", exc_info=True)
        return False

# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "ChromaWithForgetting Memory System",
        "timestamp": datetime.now().isoformat(),
        "memory_system_initialized": memory_system is not None,
        "cleanup_scheduler_running": memory_cleanup_scheduler is not None if memory_cleanup_scheduler else False
    }

@app.api_route("/v1/{path:path}", methods=["POST", "GET"])
async def proxy(request: Request, path: str):
    """
    ä»£ç†æ‰€æœ‰ /v1/* è¯·æ±‚
    1. é™¤å¯¹è¯å’Œembeddingå¤–ï¼Œå…¶ä»–openai apiå®Œæ•´é€ä¼ 
    2. embeddingæŒ‰é…ç½®å¤„ç†ï¼ˆè¿œç¨‹/æœ¬åœ°ï¼‰
    3. å¯¹è¯ï¼šæµå¼å®æ—¶è¿”å› + è®°å¿†å¢å¼ºï¼ˆæ”¶é›†ç”¨æˆ·å’ŒAIå†…å®¹ï¼‰
    """
    body = await request.body()
    
    # è®°å½•åŸºæœ¬è¯·æ±‚ä¿¡æ¯
    logger.info(f"ğŸ“¥ æ”¶åˆ°è¯·æ±‚: {request.method} /v1/{path}")
    
    # åˆ›å»ºæ–°çš„å¤´éƒ¨å­—å…¸
    new_headers = {}
    for key, value in request.headers.items():
        if key.lower() not in ['content-length', 'host', 'authorization']:
            new_headers[key] = value

    # ========== è·¯ç”±å¤„ç† ==========
    if path.startswith("embeddings"):
        # Embedding API - æŒ‰é…ç½®å¤„ç†
        return await handle_embedding_request(request, path, body, new_headers)
        
    elif path == "chat/completions":
        # Chat Completions API - æµå¼å®æ—¶ + è®°å¿†å¢å¼º
        return await handle_chat_request(request, path, body, new_headers)
        
    else:
        # å…¶ä»– API - å®Œæ•´é€ä¼ 
        return await handle_other_request(request, path, body, new_headers)

# ========== å¤„ç†å‡½æ•° ==========

async def handle_embedding_request(request, path, body, new_headers):
    """å¤„ç†embeddingè¯·æ±‚ - æŒ‰é…ç½®é€‰æ‹©è¿œç¨‹/æœ¬åœ°"""
    try:
        # è§£æè¯·æ±‚ä½“
        if body:
            body_data = json.loads(body)
            input_text = body_data.get("input", "")
            model = body_data.get("model", "")
            
            # ä½¿ç”¨æœ¬åœ°embeddingæœåŠ¡
            logger.info(" ä½¿ç”¨æœ¬åœ°embeddingæœåŠ¡")
            embedding_service = get_embedding_service()
            embeddings = embedding_service.get_embeddings([input_text])
            
            # æ„é€ å“åº”
            response_data = {
                "object": "list",
                "data": [{
                    "object": "embedding",
                    "index": 0,
                    "embedding": embeddings[0]
                }],
                "model": model,
                "usage": {
                    "prompt_tokens": len(input_text.split()),
                    "total_tokens": len(input_text.split())
                }
            }
            
            return JSONResponse(content=response_data)
                
    except Exception as e:
        logger.error(f"âŒ å¤„ç†embeddingè¯·æ±‚å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"å¤„ç†embeddingè¯·æ±‚å¤±è´¥: {str(e)}"}
        )

async def handle_chat_request(request, path, body, new_headers):
    """å¤„ç†å¯¹è¯è¯·æ±‚ - æµå¼å®æ—¶ + è®°å¿†å¢å¼º"""
    try:
        # è§£æè¯·æ±‚ä½“
        body_data = None
        user_id = None
        enhanced_query_embedding = None
        current_user_content = None
        if body:
            body_data = json.loads(body)
            # æå–ç”¨æˆ·ID
            user_id = extract_user_id_from_request(body_data)
            
            # æ›¿æ¢æ¨¡å‹åç§°
            if "model" in body_data:
                body_data["model"] = OPENAI_MODEL_NAME
            
            # è®°å¿†å¢å¼ºå¤„ç†
            enhanced_body_data, query_embedding = enhance_chat_with_memory(body_data, user_id)
            current_user_content = body_data.get("messages", [])[-1].get("content", "")
            body = json.dumps(enhanced_body_data).encode()
        
        # ä½¿ç”¨é…ç½®çš„API_KEY
        api_key = OPENAI_API_KEY
        
        # è®¾ç½®å¤´éƒ¨
        target_base = OPENAI_API_BASE.rstrip("/")
        new_headers["Authorization"] = f"Bearer {api_key}"
        if body:
            new_headers["Content-Length"] = str(len(body))
        
        url = f"{target_base}/{path}"
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæµå¼å“åº”
        is_stream = body_data and body_data.get("stream", False) if body_data else False
        
        if is_stream:
            # æµå¼å“åº”ï¼šä½¿ç”¨æ­£ç¡®çš„httpx.streamè¯­æ³•
            logger.info("ğŸŒŠ å¤„ç†æµå¼å“åº”")
            
            async def stream_wrapper():
                full_content = ""
                async with httpx.AsyncClient() as client:
                    async with client.stream(
                        method=request.method,
                        url=url,
                        headers=new_headers,
                        content=body,
                        timeout=60.0
                    ) as resp:
                        
                        async for chunk in resp.aiter_bytes():
                            # é€ä¼ æ•°æ®
                            yield chunk
                            
                            # åŒæ—¶æ”¶é›†å†…å®¹
                            chunk_str = chunk.decode('utf-8')
                            lines = chunk_str.split('\n')
                            
                            for line in lines:
                                line = line.strip()
                                if not line:
                                    continue
                                if line.startswith('data: '):
                                    chunk_data = line[6:].strip()
                                    if chunk_data == '[DONE]':
                                        break
                                    try:
                                        chunk_json = json.loads(chunk_data)
                                        if 'choices' in chunk_json and len(chunk_json['choices']) > 0:
                                            choice = chunk_json['choices'][0]
                                            delta = choice.get('delta', {})
                                            if 'content' in delta and delta['content']:
                                                chunk_content = delta['content'].strip()
                                                if chunk_content:
                                                    full_content += chunk_content
                                    except json.JSONDecodeError:
                                        continue
                
                # æµå¼ç»“æŸåå¼‚æ­¥å­˜å‚¨è®°å¿†
                if full_content and body_data:
                    asyncio.create_task(process_ai_reply_async(full_content, user_id, current_user_content))
            
            return StreamingResponse(
                stream_wrapper(),
                status_code=200,
                headers={"Content-Type": "text/plain; charset=utf-8"}
            )
        else:
            # éæµå¼å“åº”ï¼šæ­£å¸¸å¤„ç†
            async with httpx.AsyncClient(timeout=60.0) as client:
                resp = await client.request(
                    method=request.method,
                    url=url,
                    headers=new_headers,
                    content=body
                )
            
            # å¼‚æ­¥å­˜å‚¨è®°å¿†
            if resp.status_code == 200 and resp.content and body_data:
                try:
                    response_data = resp.json()
                    choices = response_data.get("choices", [])
                    if choices and len(choices) > 0:
                        message = choices[0].get("message", {})
                        content = message.get("content", "")
                        if content:
                            asyncio.create_task(process_ai_reply_async(content, user_id, current_user_content))
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†éæµå¼AIå›å¤å¤±è´¥: {e}")
            
            return Response(
                content=resp.content,
                status_code=resp.status_code,
                headers=dict(resp.headers)
            )
            
    except Exception as e:
        logger.error(f"âŒ å¤„ç†å¯¹è¯è¯·æ±‚å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"å¤„ç†å¯¹è¯è¯·æ±‚å¤±è´¥: {str(e)}"}
        )

async def handle_other_request(request, path, body, new_headers):
    """å¤„ç†å…¶ä»–API - å®Œæ•´é€ä¼ """
    try:
        # ä½¿ç”¨é…ç½®çš„API_KEY
        api_key = OPENAI_API_KEY
        
        # è®¾ç½®å¤´éƒ¨
        target_base = OPENAI_API_BASE.rstrip("/")
        new_headers["Authorization"] = f"Bearer {api_key}"
        if body:
            new_headers["Content-Length"] = str(len(body))
        
        url = f"{target_base}/{path}"
        
        # ç›´æ¥è½¬å‘
        async with httpx.AsyncClient(timeout=60.0) as client:
            resp = await client.request(
                method=request.method,
                url=url,
                headers=new_headers,
                content=body
            )
        
        return Response(
            content=resp.content,
            status_code=resp.status_code,
            headers=dict(resp.headers)
        )
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†å…¶ä»–è¯·æ±‚å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"å¤„ç†å…¶ä»–è¯·æ±‚å¤±è´¥: {str(e)}"}
        )

